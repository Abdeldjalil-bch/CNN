# ğŸï¸ Scene Classification avec Deep Learning

Classification de scÃ¨nes naturelles et urbaines utilisant des CNNs et le transfer learning avec PyTorch.

## ğŸ“Š Dataset

**Source**: [Scene Classification - Kaggle](https://www.kaggle.com/datasets/nitishabharathi/scene-classification)

- **6 classes**: Buildings, Forest, Glacier, Mountain, Sea, Street
- **Distribution**: Dataset Ã©quilibrÃ© (~2400 images par classe)
- **Dimensions**: Images de tailles variables (redimensionnÃ©es Ã  120x120 pour l'entraÃ®nement)
- **Split**: Train/Validation

## ğŸ”¬ Notebooks

### 1ï¸âƒ£ Data Exploration
- Distribution des classes (dataset Ã©quilibrÃ© confirmÃ©)
- Visualisation d'Ã©chantillons pour chaque classe
- Analyse des dimensions des images
- Statistiques descriptives

### 2ï¸âƒ£ Baseline Model
**Architecture**: CNN simple avec 2 blocs convolutifs
```
Conv2D(3â†’24) â†’ ReLU â†’ MaxPool â†’ Conv2D(24â†’8) â†’ ReLU â†’ AvgPool
â†’ Flatten â†’ Linear(4232â†’220) â†’ GELU â†’ Linear(220â†’6)
```

**RÃ©sultats**:
- âœ… **Meilleure Val Accuracy**: 81.75% (Epoch 1)
- âš ï¸ **ProblÃ¨me**: Overfitting sÃ©vÃ¨re
  - Train Loss: 0.1478 â†’ Val Loss: 0.9895 (Epoch 20)
  - Train Acc: 94.97% â†’ Val Acc: 80.87%
- **Conclusion**: Architecture trop simple, manque de rÃ©gularisation

### 3ï¸âƒ£ Deep CNN avec RBF Activation
**Architecture**: 4 blocs convolutifs + MLP avec activation RBF

**Blocs Convolutifs**:
```
Bloc 1: Conv(3â†’16) â†’ BN â†’ GELU â†’ MaxPool
Bloc 2: Conv(16â†’24) â†’ BN â†’ GELU â†’ MaxPool
Bloc 3: Conv(24â†’16) â†’ BN â†’ GELU â†’ MaxPool
Bloc 4: Conv(16â†’8) â†’ BN â†’ GELU â†’ MaxPool
```

**Classificateur MLP**:
```
Linear(392â†’128) â†’ RBF â†’ Linear(128â†’64) â†’ ReLU â†’ Linear(64â†’6)
```

**Augmentation de donnÃ©es**: 
- âœ… MixUp
- âœ… CutMix
- âœ… Random Horizontal Flip
- âœ… Random Rotation (Â±10Â°)
- âœ… Color Jitter

**RÃ©sultats**:
- âœ… **Best Val Loss**: 0.4214 (Epoch 18)
- âœ… **Best Val Accuracy**: 86.39% (Epoch 18)
- âœ… **Train Accuracy**: 80.26%
- â±ï¸ **Temps d'entraÃ®nement**: 54 minutes (20 epochs)
- **Force**: Bon Ã©quilibre train/val, pas d'overfitting grÃ¢ce Ã  MixUp/CutMix
- **Innovation**: Utilisation de RBF (Radial Basis Function) comme activation

### 4ï¸âƒ£ Transfer Learning - ResNet18
**Architecture**: ResNet18 prÃ©-entraÃ®nÃ© (ImageNet) avec fine-tuning complet

**Configuration**:
```python
model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
# Tous les paramÃ¨tres dÃ©gelÃ©s
for param in model.parameters():
    param.requires_grad = True
# Adaptation de la tÃªte de classification
model.fc = nn.Linear(512, 6)
```

**HyperparamÃ¨tres**:
- Learning Rate: 1e-4 (plus faible pour prÃ©server les poids prÃ©-entraÃ®nÃ©s)
- Patience: 4 epochs (Early Stopping)

**RÃ©sultats**:
- ğŸ† **Best Val Accuracy**: 93.19% (Epoch 11)
- âš ï¸ **Best Val Loss**: 0.5751 (Epoch 11)
- âœ… **Train Accuracy**: 91.31%
- â±ï¸ **Temps d'entraÃ®nement**: 227 minutes (15 epochs avant early stopping)

**Observations**:
- âœ… **Meilleure accuracy** de tous les modÃ¨les (+6.8% vs Deep CNN)
- âš ï¸ **ProblÃ¨me de Loss**: La validation loss ne diminue pas autant qu'attendu (0.5751 vs 0.4214 pour Deep CNN)
- **HypothÃ¨se**: Le modÃ¨le apprend bien les classes (accuracy Ã©levÃ©e) mais a moins confiance dans ses prÃ©dictions (loss plus Ã©levÃ©e)
- **Temps**: ~4x plus long que le Deep CNN custom

## ğŸ“ˆ Comparaison des ModÃ¨les

| ModÃ¨le | Val Accuracy | Val Loss | Train Time | Overfitting |
|--------|--------------|----------|------------|-------------|
| **Baseline CNN** | 81.75% | 0.9895 | ~30 min | âŒ SÃ©vÃ¨re |
| **Deep CNN + RBF** | 86.39% | 0.4214 | 54 min | âœ… Minimal |
| **ResNet18** | **93.19%** | 0.5751 | 227 min | âš ï¸ LÃ©ger |

## ğŸ¯ RÃ©sultats ClÃ©s

### ğŸ¥‡ Meilleur ModÃ¨le: ResNet18
- **+11.44%** vs Baseline
- **+6.80%** vs Deep CNN custom
- BÃ©nÃ©ficie du transfer learning d'ImageNet

### ğŸ… Meilleur Rapport Performance/Temps: Deep CNN
- 86.39% d'accuracy en seulement 54 minutes
- Loss la plus faible (0.4214)
- Pas d'overfitting grÃ¢ce Ã  MixUp/CutMix
- Architecture originale avec RBF activation

## ğŸ› ï¸ Technologies

```
Python 3.10+
PyTorch 2.0+
torchvision
numpy
pandas
matplotlib
seaborn
tqdm
```

## ğŸ“¦ Installation

```bash
# Cloner le repository
git clone https://github.com/votre-username/scene-classification.git
cd scene-classification

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger le dataset depuis Kaggle
# Placer dans ./data/
```

## ğŸš€ Utilisation

```python
# Charger un modÃ¨le prÃ©-entraÃ®nÃ©
import torch
from models import CustomCNN  # ou ResNet18

model = CustomCNN(num_classes=6)
model.load_state_dict(torch.load('models/best_deep_cnn.pth'))
model.eval()

# PrÃ©dire sur une nouvelle image
# (voir notebooks pour exemple complet)
```

## ğŸ“Š Techniques ClÃ©s

### Data Augmentation
- **MixUp**: Interpolation linÃ©aire entre paires d'images
- **CutMix**: Remplacement de rÃ©gions rectangulaires entre images
- Transformations classiques (flip, rotation, color jitter)

### RÃ©gularisation
- Batch Normalization dans tous les blocs convolutifs
- Early Stopping (patience = 4-7 epochs)
- ReduceLROnPlateau scheduler
- Dropout implicite via MixUp/CutMix

### Innovation
- **RBF Activation**: Radial Basis Function comme couche d'activation non-linÃ©aire
  ```python
  RBF(x) = exp(-Î³(x - center)Â²)
  ```

## ğŸ” Observations et Enseignements

1. **Transfer Learning est puissant**: +6.8% d'amÃ©lioration avec ResNet18
2. **MixUp/CutMix rÃ©duisent l'overfitting**: Ã‰cart train/val minimal
3. **RBF Activation fonctionne**: Alternative intÃ©ressante Ã  ReLU/GELU
4. **Trade-off temps/performance**: Deep CNN custom = excellent compromis



---

â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !